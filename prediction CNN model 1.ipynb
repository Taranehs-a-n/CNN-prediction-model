{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8d5sVcpWXhUIfOVRX97qZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "fN6Q6DJg511V"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aXLSVrSdEBJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the class labels\n",
        "class_labels = ['class 1', 'class 2', 'class 3', 'class 4', 'class 5']"
      ],
      "metadata": {
        "id": "T-IJl09KEsMR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "data_dir = '/content/drive/MyDrive/data'\n",
        "all_images = []\n",
        "all_labels = []\n"
      ],
      "metadata": {
        "id": "h6DMxc_BGd2T"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height,img_width=300,300\n",
        "batch_size=32\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "R19_RVECMf27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "rjv13oJTOdG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure with a given size\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Iterate through the first batch of images and labels\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):  # Changed the range to show 9 images (3x3 grid)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Display the image\n",
        "\n",
        "        # Check the label and set the title accordingly\n",
        "        if labels[i] < 5:\n",
        "            class_num = labels[i] + 1  # Convert the label to class number (1-based index)\n",
        "        else:\n",
        "            class_num = 5  # If the label is not in the range of classes, set it as the last class\n",
        "\n",
        "        plt.title(f\"class {class_num}\")  # Display the class number in the title\n",
        "        plt.axis(\"off\")  # Remove axis from the plot\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tSbgYrI8RtMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(300,300,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "])\n"
      ],
      "metadata": {
        "id": "nMYZZlVzSDpF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8vbZvw6TZJJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the optimizer with the specified learning rate\n",
        "adam_optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile the model using the defined optimizer\n",
        "model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Continue with the model training\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B9P1mZD5exee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g5ddtBNte_E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def load_and_preprocess_image(model, image_path):\n",
        "    \"\"\"\n",
        "    Loads the image from the given path, preprocesses it according to the model's input shape,\n",
        "    and returns the preprocessed image and its prediction.\n",
        "    \"\"\"\n",
        "    # Load the image and convert it to a numpy array\n",
        "    image = load_img(\n",
        "        image_path,\n",
        "        target_size=tuple(model.input_shape[1:3]),\n",
        "        resolve_ndarray=True,  # Return the image as a numpy array directly\n",
        "    )\n",
        "\n",
        "    # Perform any additional preprocessing if required\n",
        "    preprocessed_image = preprocess_if_needed(image, model)\n",
        "\n",
        "    # Make predictions on the preprocessed image\n",
        "    predictions = model.predict(preprocessed_image)"
      ],
      "metadata": {
        "id": "aTBq__ljfJ5a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the resized image\n",
        "prediction = predict_on_image(model, '/content/drive/MyDrive/path/to/your/image.jpg')\n",
        "print(f'Prediction: {prediction}')"
      ],
      "metadata": {
        "id": "VB3cWOYtjg62"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}